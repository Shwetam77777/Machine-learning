import pandas as pd
import numpy as np
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

dataset = load_iris()
def cost_function(X,w,bias,y):
    N = X.shape[0]
    z=net_input(X,w,bias)
    y_enc=one_hot_encode(y)
    y_pred=softmax(z)
    cost = -(1/N)*np.sum(y_enc*np.log2(y_pred))
    gradient = -(1/N)*np.dot(X.T,(y_enc-y_pred))
    return cost,gradient

def net_input(X,w,bias):
    return np.dot(X,w)+bias

def softmax(z):
    return (np.exp(z.T)/(np.sum(np.exp(z),axis=1))).T

def class_labels(cp):
    return cp.argmax(axis=1)

X =  dataset.data
y = dataset.target
weight = np.full(shape=(4,3),fill_value=0.1)
bias = np.array([0.1,0.1,0.1])

z = net_input(X,weight,bias)
cp=softmax(z)
y_pred=class_labels(cp)
#print(y_pred,"--> ",y)
#print(sum(y==y_pred)/len(y))

def one_hot_encode(y):
    y_enc=pd.get_dummies(y)
    return np.array(y_enc)

def gradient_descent():
    global X,weight,bias,y
    iterations = 1000
    learning_rate = 0.05
    i_lst,c_lst = [],[]
    for i in range(iterations):
        cost,gradient=cost_function(X,weight,bias,y)
        i_lst.append(i)
        c_lst.append(cost)
        weight = weight - (learning_rate*gradient)

    plt.xlabel("No. of Iterations")
    plt.ylabel("Cost")
    plt.plot(i_lst,c_lst)
    plt.show()

gradient_descent()
print(weight)
def accuracy():
    z=net_input(X,weight,bias)
    cp=softmax(z)
    y_pred=class_labels(cp)
    return sum(y==y_pred)/len(y)

print(round(accuracy(),2))

model=LogisticRegression()
model.fit(X,y)
print(model.score(X,y))
print(model.coef_)